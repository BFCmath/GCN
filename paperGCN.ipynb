{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper link: [here](https://arxiv.org/pdf/1609.02907)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary for what I can understand from the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization \n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*Y3IcRT75O6f2NC9BFGhq3g.png\" width=\"600\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![demo](image/demo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Meaning of the convolutions on Graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![convolution function](image/convolution_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "+ A: adjacency matrix \n",
    "+ $\\bar{A}$: adjacency matrix with self-connections\n",
    "+ D: $D_{ii} = \\sum{A_i}$ \n",
    "+ H = X\n",
    "+ W: weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ex1](image/ex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ex2](image/ex2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### What is D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "the D is actually a way to normalize the A (turning them into prob matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Why not $D^{-1}*A$ but $D^{-0.5}AD^{-0.5}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "both way can normalize A, but the paper prefers the later because it can reduce gradient exploding/vanishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### The similarity between GCN and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/GCN_vs_CNN_overview.png\" width=\"500\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "the $D^{-0.5}AD^{-0.5}$ is just masked as 1 if two nodes are neighbors, and then normalize it to calculate the proba.  \n",
    "Another way to understand this is think its like the following kernel:\n",
    "\n",
    "$ \\frac{1}{9} \\frac{1}{9} \\frac{1}{9}$  \n",
    "\n",
    "$ \\frac{1}{9} \\frac{1}{9} \\frac{1}{9}$  \n",
    "\n",
    "$ \\frac{1}{9} \\frac{1}{9} \\frac{1}{9}$  \n",
    "\n",
    "\n",
    "its calculate the avg between the current cell to surrounding, and the convolution calculation in the graph is exactly the same!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Treating the GNN just like CNN with the number of node the same in each layer and the vector inside of the node will gradually reduce, we can extract the last layer as a feature-space-extracted matrix (just like CNN!!!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![model](https://miro.medium.com/v2/resize:fit:1400/1*7vMs4Ym_W1FlqcuI7PulSQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SemiSupervised Graph problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![problem](image/problem.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "+ Memory requirement: dont support mini-batch\n",
    "+ Directed edges and edge features: just undirected graph\n",
    "+ Limiting assumption: all contribute is the same\n",
    "+ Transductive setting: retrain when add nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphSage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an inductive learning method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper [here](https://arxiv.org/abs/1706.02216)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](image/graphsage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "##  Inductive and tranductive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ inductive: adaptable to unseen data\n",
    "+ tranductive: unadaptable to unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](image/embed_GSAGE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "+ k: for each aggregate (could be mean, pool or lstm,...)\n",
    "+ v: nodes in graph\n",
    "+ for each v, do aggregate(all previous value of neighbor nodes)\n",
    "+ then concat the previous value of v with that result, then go through non-linear activate function \n",
    "+ normalize of v"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
